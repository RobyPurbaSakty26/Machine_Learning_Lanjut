{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('yelp_labelled.txt', names=['sentence', 'label'], sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengubah seluruh text kedalam bentuk lowercase\n",
    "df['sentence'] = df['sentence'].str.lower()\n",
    " \n",
    "# Menghilangkan stopwords\n",
    "stop_word = set(stopwords.words('english'))\n",
    " \n",
    "df['sentence'] = df['sentence'].apply(lambda x:' '.join([word for word in x.split() if word not in (stop_word)]))\n",
    " \n",
    "# Melakukan split dataset\n",
    "sentence = df['sentence'].values\n",
    "label = df['label'].values\n",
    " \n",
    "sentence_train, sentence_test, label_train, label_test = train_test_split(sentence, label, test_size=0.2, shuffle=False)\n",
    " \n",
    "# Membuat tokenisasi\n",
    "filt = '!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ' # Filter untuk menghilangkan symbols\n",
    " \n",
    "tokenizer = Tokenizer(num_words=2000, oov_token=\"<OOV>\", filters=filt)\n",
    " \n",
    "tokenizer.fit_on_texts(sentence_train)\n",
    " \n",
    "# Menyimpan word_index kedalam sebuah file json\n",
    "word_index = tokenizer.word_index\n",
    " \n",
    "with open('word_index.json', 'w') as fp:\n",
    "    json.dump(word_index, fp)\n",
    " \n",
    "# Membuat sequences dan melakukan padding\n",
    "train_sekuens = tokenizer.texts_to_sequences(sentence_train)\n",
    "test_sekuens = tokenizer.texts_to_sequences(sentence_test)\n",
    " \n",
    "train_padded = pad_sequences(train_sekuens,\n",
    "                             maxlen=20,\n",
    "                             padding='post',\n",
    "                             truncating='post')\n",
    "test_padded = pad_sequences(test_sekuens,\n",
    "                            maxlen=20,\n",
    "                            padding='post',\n",
    "                            truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "25/25 [==============================] - 2s 30ms/step - loss: 0.6921 - accuracy: 0.5288 - val_loss: 0.7111 - val_accuracy: 0.2400\n",
      "Epoch 2/30\n",
      "25/25 [==============================] - 1s 38ms/step - loss: 0.6866 - accuracy: 0.5650 - val_loss: 0.7415 - val_accuracy: 0.2400\n",
      "Epoch 3/30\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 0.6803 - accuracy: 0.5650 - val_loss: 0.7688 - val_accuracy: 0.2400\n",
      "Epoch 4/30\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.6691 - accuracy: 0.5650 - val_loss: 0.7632 - val_accuracy: 0.2400\n",
      "Epoch 5/30\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.6329 - accuracy: 0.6187 - val_loss: 0.7435 - val_accuracy: 0.2900\n",
      "Epoch 6/30\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5416 - accuracy: 0.7900 - val_loss: 0.7064 - val_accuracy: 0.4450\n",
      "Epoch 7/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.3939 - accuracy: 0.8925 - val_loss: 0.6096 - val_accuracy: 0.6600\n",
      "Epoch 8/30\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.2524 - accuracy: 0.9438 - val_loss: 0.5376 - val_accuracy: 0.7600\n",
      "Epoch 9/30\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.1628 - accuracy: 0.9588 - val_loss: 0.5675 - val_accuracy: 0.7550\n",
      "Epoch 10/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1066 - accuracy: 0.9787 - val_loss: 0.6795 - val_accuracy: 0.7100\n",
      "Epoch 11/30\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0776 - accuracy: 0.9875 - val_loss: 0.6973 - val_accuracy: 0.7400\n",
      "Epoch 12/30\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0602 - accuracy: 0.9887 - val_loss: 0.7089 - val_accuracy: 0.7500\n",
      "Epoch 13/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0458 - accuracy: 0.9937 - val_loss: 0.7531 - val_accuracy: 0.7500\n",
      "Epoch 14/30\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0384 - accuracy: 0.9912 - val_loss: 0.6571 - val_accuracy: 0.7650\n",
      "Epoch 15/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0319 - accuracy: 0.9937 - val_loss: 0.7037 - val_accuracy: 0.7600\n",
      "Epoch 16/30\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0295 - accuracy: 0.9937 - val_loss: 0.8488 - val_accuracy: 0.7500\n",
      "Epoch 17/30\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0223 - accuracy: 0.9950 - val_loss: 0.8518 - val_accuracy: 0.7500\n",
      "Epoch 18/30\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0220 - accuracy: 0.9962 - val_loss: 0.9878 - val_accuracy: 0.7100\n",
      "Epoch 19/30\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0172 - accuracy: 0.9962 - val_loss: 0.8533 - val_accuracy: 0.7600\n",
      "Epoch 20/30\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0155 - accuracy: 0.9962 - val_loss: 0.9478 - val_accuracy: 0.7500\n",
      "Epoch 21/30\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0141 - accuracy: 0.9962 - val_loss: 0.9915 - val_accuracy: 0.7400\n",
      "Epoch 22/30\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0137 - accuracy: 0.9962 - val_loss: 0.8620 - val_accuracy: 0.7600\n",
      "Epoch 23/30\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.0123 - accuracy: 0.9975 - val_loss: 1.0574 - val_accuracy: 0.7250\n",
      "Epoch 24/30\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0155 - accuracy: 0.9912 - val_loss: 0.9998 - val_accuracy: 0.7400\n",
      "Epoch 25/30\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.0121 - accuracy: 0.9975 - val_loss: 1.0695 - val_accuracy: 0.7200\n",
      "Epoch 26/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0102 - accuracy: 0.9975 - val_loss: 1.1135 - val_accuracy: 0.7250\n",
      "Epoch 27/30\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.0088 - accuracy: 0.9975 - val_loss: 1.0635 - val_accuracy: 0.7400\n",
      "Epoch 28/30\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 1.1534 - val_accuracy: 0.7250\n",
      "Epoch 29/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 1.0162 - val_accuracy: 0.7500\n",
      "Epoch 30/30\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0077 - accuracy: 0.9987 - val_loss: 1.0516 - val_accuracy: 0.7450\n"
     ]
    }
   ],
   "source": [
    "# Membuat model\n",
    "model = tf.keras.Sequential([\n",
    "    Embedding(2000, 20, input_length=20),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    " \n",
    "# Compile model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    " \n",
    "# Train model\n",
    "num_epochs = 30\n",
    "history = model.fit(train_padded, label_train,\n",
    "                    epochs=num_epochs,\n",
    "                    validation_data=(test_padded, label_test),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflowjs"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached tensorflowjs-3.20.0-py3-none-any.whl (81 kB)\n",
      "Collecting jax>=0.3.16\n",
      "  Using cached jax-0.3.19.tar.gz (1.1 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting importlib_resources>=5.9.0\n",
      "  Using cached importlib_resources-5.9.0-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: tensorflow<3,>=2.1.0 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from tensorflowjs) (2.9.0)\n",
      "Requirement already satisfied: tensorflow-hub<0.13,>=0.7.0 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from tensorflowjs) (0.12.0)\n",
      "Requirement already satisfied: packaging~=20.9 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from tensorflowjs) (20.9)\n",
      "Requirement already satisfied: six<2,>=1.12.0 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from tensorflowjs) (1.16.0)\n",
      "Collecting flax>=0.5.3\n",
      "  Using cached flax-0.6.0-py3-none-any.whl (180 kB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Using cached protobuf-3.19.5-cp310-cp310-win_amd64.whl (895 kB)\n",
      "Requirement already satisfied: numpy>=1.12 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from flax>=0.5.3->tensorflowjs) (1.23.3)\n",
      "Collecting optax\n",
      "  Using cached optax-0.1.3-py3-none-any.whl (145 kB)\n",
      "Collecting msgpack\n",
      "  Using cached msgpack-1.0.4-cp310-cp310-win_amd64.whl (61 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from flax>=0.5.3->tensorflowjs) (4.3.0)\n",
      "Collecting PyYAML>=5.4.1\n",
      "  Using cached PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from flax>=0.5.3->tensorflowjs) (3.6.0)\n",
      "Collecting rich~=11.1\n",
      "  Using cached rich-11.2.0-py3-none-any.whl (217 kB)\n",
      "Requirement already satisfied: absl-py in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from jax>=0.3.16->tensorflowjs) (1.2.0)\n",
      "Requirement already satisfied: opt_einsum in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from jax>=0.3.16->tensorflowjs) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.5 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from jax>=0.3.16->tensorflowjs) (1.9.1)\n",
      "Collecting etils[epath]\n",
      "  Using cached etils-0.8.0-py3-none-any.whl (127 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from packaging~=20.9->tensorflowjs) (3.0.9)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.0.1)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.48.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (14.0.6)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.14.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.7.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.27.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.9.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (58.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (0.37.1)\n",
      "Collecting commonmark<0.10.0,>=0.9.0\n",
      "  Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from rich~=11.1->flax>=0.5.3->tensorflowjs) (2.13.0)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.0 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from rich~=11.1->flax>=0.5.3->tensorflowjs) (0.4.5)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (2.11.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (2.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (2.28.1)\n",
      "Collecting zipp\n",
      "  Using cached zipp-3.8.1-py3-none-any.whl (5.6 kB)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from matplotlib->flax>=0.5.3->tensorflowjs) (4.37.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from matplotlib->flax>=0.5.3->tensorflowjs) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from matplotlib->flax>=0.5.3->tensorflowjs) (1.0.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from matplotlib->flax>=0.5.3->tensorflowjs) (9.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from matplotlib->flax>=0.5.3->tensorflowjs) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from matplotlib->flax>=0.5.3->tensorflowjs) (0.11.0)\n",
      "Collecting chex>=0.0.4\n",
      "  Using cached chex-0.1.5-py3-none-any.whl (85 kB)\n",
      "Collecting optax\n",
      "  Using cached optax-0.1.2-py3-none-any.whl (140 kB)\n",
      "  Using cached optax-0.1.1-py3-none-any.whl (136 kB)\n",
      "  Using cached optax-0.1.0-py3-none-any.whl (126 kB)\n",
      "  Using cached optax-0.0.91-py3-none-any.whl (126 kB)\n",
      "  Using cached optax-0.0.9-py3-none-any.whl (118 kB)\n",
      "  Using cached optax-0.0.8-py3-none-any.whl (113 kB)\n",
      "  Using cached optax-0.0.6-py3-none-any.whl (96 kB)\n",
      "  Using cached optax-0.0.5-py3-none-any.whl (89 kB)\n",
      "  Using cached optax-0.0.3-py3-none-any.whl (73 kB)\n",
      "  Using cached optax-0.0.2-py3-none-any.whl (54 kB)\n",
      "  Using cached optax-0.0.1-py3-none-any.whl (49 kB)\n",
      "INFO: pip is looking at multiple versions of msgpack to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting msgpack\n",
      "  Using cached msgpack-1.0.3-cp310-cp310-win_amd64.whl (69 kB)\n",
      "INFO: pip is looking at multiple versions of matplotlib to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.6.0-cp310-cp310-win_amd64.whl (7.2 MB)\n",
      "INFO: pip is looking at multiple versions of etils[epath] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting etils[epath]\n",
      "  Using cached etils-0.7.1-py3-none-any.whl (124 kB)\n",
      "  Using cached etils-0.7.0-py3-none-any.whl (124 kB)\n",
      "  Using cached etils-0.6.0-py3-none-any.whl (98 kB)\n",
      "  Using cached etils-0.5.1-py3-none-any.whl (87 kB)\n",
      "INFO: pip is looking at multiple versions of wrapt to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.14.1-cp310-cp310-win_amd64.whl (35 kB)\n",
      "INFO: pip is looking at multiple versions of typing-extensions to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting typing-extensions>=4.1.1\n",
      "  Using cached typing_extensions-4.3.0-py3-none-any.whl (25 kB)\n",
      "  Using cached typing_extensions-4.2.0-py3-none-any.whl (24 kB)\n",
      "  Using cached typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
      "INFO: pip is looking at multiple versions of termcolor to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.0.1-py3-none-any.whl (5.4 kB)\n",
      "INFO: pip is looking at multiple versions of typing-extensions to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of tensorflow-io-gcs-filesystem to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.27.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "INFO: pip is looking at multiple versions of tensorflow-estimator to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Using cached tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of tensorboard to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorboard<2.10,>=2.9\n",
      "  Using cached tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting scipy>=1.5\n",
      "  Using cached scipy-1.9.1-cp310-cp310-win_amd64.whl (38.6 MB)\n",
      "INFO: pip is looking at multiple versions of rich to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting rich~=11.1\n",
      "  Using cached rich-11.1.0-py3-none-any.whl (216 kB)\n",
      "INFO: pip is looking at multiple versions of pyyaml to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting PyYAML>=5.4.1\n",
      "  Using cached PyYAML-5.4.1.tar.gz (175 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "INFO: pip is looking at multiple versions of pyparsing to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pyparsing>=2.0.2\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "INFO: pip is looking at multiple versions of opt-einsum to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opt_einsum\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "INFO: pip is looking at multiple versions of numpy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting numpy>=1.12\n",
      "  Using cached numpy-1.23.3-cp310-cp310-win_amd64.whl (14.6 MB)\n",
      "INFO: pip is looking at multiple versions of libclang to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "INFO: pip is looking at multiple versions of keras-preprocessing to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "INFO: pip is looking at multiple versions of keras to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting keras<2.10.0,>=2.9.0rc0\n",
      "  Using cached keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "INFO: pip is looking at multiple versions of h5py to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting h5py>=2.9.0\n",
      "  Using cached h5py-3.7.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "INFO: pip is looking at multiple versions of grpcio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.49.1-cp310-cp310-win_amd64.whl (3.6 MB)\n",
      "INFO: pip is looking at multiple versions of google-pasta to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "INFO: pip is looking at multiple versions of gast to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "INFO: pip is looking at multiple versions of flatbuffers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting flatbuffers<2,>=1.12\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "INFO: pip is looking at multiple versions of astunparse to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "INFO: pip is looking at multiple versions of absl-py to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting absl-py\n",
      "  Using cached absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "INFO: pip is looking at multiple versions of tensorflow-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflow-hub<0.13,>=0.7.0\n",
      "  Using cached tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflow<3,>=2.1.0\n",
      "  Using cached tensorflow-2.10.0-cp310-cp310-win_amd64.whl (455.9 MB)\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Using cached keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Using cached flatbuffers-22.9.24-py2.py3-none-any.whl (26 kB)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Using cached tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "Collecting tensorflow<3,>=2.1.0\n",
      "  Using cached tensorflow-2.9.2-cp310-cp310-win_amd64.whl (444.2 MB)\n",
      "  Using cached tensorflow-2.9.1-cp310-cp310-win_amd64.whl (444.1 MB)\n",
      "  Using cached tensorflow-2.9.0-cp310-cp310-win_amd64.whl (444.1 MB)\n",
      "  Using cached tensorflow-2.8.3-cp310-cp310-win_amd64.whl (438.4 MB)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Using cached tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Collecting tensorflow-estimator<2.9,>=2.8\n",
      "  Using cached tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Using cached keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting tensorflow<3,>=2.1.0\n",
      "  Using cached tensorflow-2.8.2-cp310-cp310-win_amd64.whl (438.3 MB)\n",
      "  Using cached tensorflow-2.8.1-cp310-cp310-win_amd64.whl (438.3 MB)\n",
      "INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached tensorflow-2.8.0-cp310-cp310-win_amd64.whl (438.0 MB)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Using cached tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "INFO: pip is looking at multiple versions of tf-estimator-nightly to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of six to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting six<2,>=1.12.0\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of protobuf to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Using cached protobuf-3.19.4-cp310-cp310-win_amd64.whl (895 kB)\n",
      "INFO: pip is looking at multiple versions of packaging to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting packaging~=20.9\n",
      "  Using cached packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
      "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jax>=0.3.16\n",
      "  Using cached jax-0.3.17.tar.gz (1.1 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached jax-0.3.16.tar.gz (1.0 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "INFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of importlib-resources to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of flax to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting flax>=0.5.3\n",
      "  Using cached flax-0.5.3-py3-none-any.whl (202 kB)\n",
      "Collecting tensorstore\n",
      "  Using cached tensorstore-0.1.26-cp310-cp310-win_amd64.whl (6.1 MB)\n",
      "INFO: pip is looking at multiple versions of tf-estimator-nightly to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of tensorflowjs to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflowjs\n",
      "  Using cached tensorflowjs-3.19.0-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: protobuf==3.20.0 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from tensorflowjs) (3.20.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (1.26.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\roby pc\\documents\\programing\\machine_learning_lanjut\\ini-env\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (3.2.1)\n",
      "Installing collected packages: tensorflowjs\n",
      "Successfully installed tensorflowjs-3.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 16:09:30.213386: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-09-28 16:09:30.214532: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Convert model.h5 to model\n",
    "!tensorflowjs_converter --input_format=keras model.h5 tfjs_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('ini-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f478e80f65e8a33a5f70bec68c4d99c8650f3f9700a477b28bc1fa664e2a7ed6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
